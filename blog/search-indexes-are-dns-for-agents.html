<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Search Indexes Are the DNS Layer for AI Agents - DevExp.ai</title>
    <meta name="description" content="Surprise! Agents don't browse. They are routed. I tried to build a handshake protocol and discovered agents can't actually navigate the web.">

    <link href="https://fonts.googleapis.com/css2?family=Source+Serif+4:wght@400;500;600;700&family=JetBrains+Mono:wght@400&display=swap" rel="stylesheet">

    <style>
        :root {
            --color-primary: hsl(24, 90%, 52%);
            --color-accent: hsl(170, 85%, 42%);
            --color-background: #030712;
            --color-surface: rgba(255, 255, 255, 0.03);
            --color-border: rgba(255, 255, 255, 0.1);
            --color-text: #ffffff;
            --color-text-muted: rgba(255, 255, 255, 0.7);
            --color-text-subtle: rgba(255, 255, 255, 0.5);
        }

        * { box-sizing: border-box; margin: 0; padding: 0; }

        body {
            font-family: 'Source Serif 4', Georgia, serif;
            background: var(--color-background);
            color: var(--color-text);
            line-height: 1.8;
            font-size: 18px;
        }

        .nav { border-bottom: 1px solid var(--color-border); padding: 20px 0; }
        .container { max-width: 700px; margin: 0 auto; padding: 0 24px; }
        .nav-inner { display: flex; justify-content: space-between; align-items: center; max-width: 700px; margin: 0 auto; padding: 0 24px; }
        .nav a { color: var(--color-text-muted); text-decoration: none; }
        .nav a:hover { color: var(--color-text); }
        .nav-brand { color: var(--color-primary); font-weight: 700; font-size: 1.25rem; }
        .nav-links { display: flex; gap: 24px; font-size: 0.9rem; }

        header { padding: 80px 0 40px; }
        .meta { color: var(--color-text-subtle); font-size: 0.9rem; margin-bottom: 16px; }

        h1 { font-size: 2.25rem; font-weight: 600; line-height: 1.2; margin-bottom: 24px; }

        article { padding-bottom: 80px; }
        h2 { font-size: 1.4rem; font-weight: 600; margin: 48px 0 24px; color: var(--color-text); }
        p { margin-bottom: 24px; color: var(--color-text-muted); }

        ul, ol { margin-bottom: 24px; padding-left: 24px; color: var(--color-text-muted); }
        li { margin-bottom: 8px; }

        blockquote {
            margin: 32px 0;
            padding: 20px 24px;
            border-left: 3px solid var(--color-primary);
            background: var(--color-surface);
        }
        blockquote p { margin: 0; font-style: italic; }

        code {
            font-family: 'JetBrains Mono', monospace;
            background: var(--color-surface);
            padding: 2px 6px;
            font-size: 0.85em;
            color: var(--color-accent);
        }

        pre {
            background: var(--color-surface);
            border: 1px solid var(--color-border);
            padding: 20px;
            margin: 24px 0;
            overflow-x: auto;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.85rem;
            line-height: 1.6;
            color: var(--color-text-muted);
        }
        pre code { background: none; padding: 0; color: inherit; }

        strong { color: var(--color-text); }

        hr { border: none; border-top: 1px solid var(--color-border); margin: 48px 0; }

        .about-section {
            border-top: 1px solid var(--color-border);
            padding: 48px 0;
            margin-top: 48px;
        }
        .about-section h3 {
            font-size: 1.1rem;
            font-weight: 600;
            margin-bottom: 16px;
            color: var(--color-text);
        }
        .about-section p {
            font-size: 0.95rem;
            margin-bottom: 16px;
        }
        .cta-link {
            display: inline-block;
            color: var(--color-primary);
            font-weight: 500;
            text-decoration: none;
        }
        .cta-link:hover {
            text-decoration: underline;
        }

        .footer { border-top: 1px solid var(--color-border); padding: 40px 0; text-align: center; color: var(--color-text-subtle); font-size: 0.875rem; }
        .footer a { color: var(--color-text-muted); text-decoration: none; margin: 0 12px; }

        @media (max-width: 600px) {
            h1 { font-size: 1.75rem; }
            body { font-size: 16px; }
        }
    </style>
</head>
<body>
    <nav class="nav">
        <div class="nav-inner">
            <a href="/" class="nav-brand">DevExp.ai</a>
            <div class="nav-links">
                <a href="/blog.html">Blog</a>
                <a href="/#demo">Contact</a>
            </div>
        </div>
    </nav>

    <header>
        <div class="container">
            <div class="meta">February 3, 2026</div>
            <h1>Search Indexes Are the DNS Layer for AI Agents</h1>
        </div>
    </header>

    <article>
        <div class="container">

<p>I tried to build a handshake protocol for AI agents. Put a token in <code>/.well-known/agent.json</code>, told the agent to fetch it, extract the token, and include it in the next request. Basic stuff. Four HTTP calls.</p>

<p>It didn't work.</p>

<p>Not because the protocol was wrong, but because ChatGPT straight up told me it can't do that. Here's what it said:</p>

<blockquote>
<p>"I do not behave like a browser or crawler. I behave like a retrieval-mediated agent. Meaning: search index → allowed fetch → parse. NOT: navigate → execute JS → explore."</p>
</blockquote>

<p>And then this:</p>

<blockquote>
<p>"Search indexes are currently acting as the de facto DNS layer for agents."</p>
</blockquote>

<p>I've been thinking about this for days.</p>

<h2>What's actually happening</h2>

<p>When you ask ChatGPT something that needs web content, you probably imagine:</p>

<pre><code>agent → website</code></pre>

<p>What's actually happening:</p>

<pre><code>agent
  ↓
search index (Bing, usually)
  ↓
fetch layer (grabs URLs from search results)
  ↓
your content (maybe)</code></pre>

<p>The agent doesn't decide to visit your site. The search index decides whether your site gets visited. The agent just sees whatever the fetch layer hands it.</p>

<p>This has some weird implications.</p>

<h2>You can't handshake with something that can't navigate</h2>

<p>My handshake protocol required the agent to:</p>

<ol>
<li>Fetch URL A</li>
<li>Extract data from the response</li>
<li>Use that data to construct URL B</li>
<li>Fetch URL B</li>
</ol>

<p>Agents can't do step 3. Each fetch is independent. There's no state between requests. The agent can't take something it learned from one HTTP response and use it to construct the next request.</p>

<p>This isn't a bug. It's the architecture. The fetch layer is stateless by design.</p>

<h2>All that llms.txt stuff doesn't matter yet</h2>

<p>I've been building <code>llms.txt</code> files, <code>agent.json</code> manifests, structured context endpoints. Everyone's doing this. It feels like the right thing to do.</p>

<p>But here's the problem: agents don't look for these files. They don't navigate to <code>/.well-known/</code> anything. They query a search index and fetch whatever comes back.</p>

<p>If your <code>llms.txt</code> isn't in the search results for the query the agent is running, the agent will never see it.</p>

<p>All the work on agent-readable formats is Gate 2 work (can the agent understand you?) when we haven't solved Gate 1 (can the agent reach you?). Gate 1 is currently outsourced entirely to search indexes.</p>

<h2>What's missing</h2>

<p>The agent told me something that stuck:</p>

<blockquote>
<p>"The real protocol layer for the agent web may end up looking far closer to BGP + TLS than to sitemap + robots.txt."</p>
</blockquote>

<p>We're missing the infrastructure. Specifically:</p>

<ul>
<li><strong>Agent DNS:</strong> How does an agent resolve "I need the canonical endpoint for Stripe's payment API" into an actual URL? Right now: search for it. That's not a protocol, that's a hack.</li>
<li><strong>Agent TLS:</strong> How does an agent know the endpoint it's talking to is actually Stripe and not someone pretending to be Stripe? Right now: it doesn't. It trusts whatever the search index returned.</li>
<li><strong>Capability negotiation:</strong> How does an agent discover what an endpoint can do before calling it? Right now: hope there's an OpenAPI spec somewhere, or just try stuff.</li>
</ul>

<p>MCP is a piece of the puzzle but it's more like HTTP than DNS. It tells you how to talk to an endpoint, not how to find and verify endpoints in the first place.</p>

<h2>Where this probably goes</h2>

<p>Prediction: within a few years, serious agent-facing endpoints will need to publish something like a signed manifest. Identity, capabilities, trust chain, maybe pricing. Before any agent action happens.</p>

<p>Like how TLS went from optional to required. First it was "nice to have HTTPS." Then browsers started warning on HTTP. Then HTTP basically stopped working for anything real.</p>

<p>Same thing will happen with agent endpoints. Right now, agents will call anything the search index gives them. That won't last. Too much attack surface. Too easy to impersonate.</p>

<h2>What to do now</h2>

<p>Short term: SEO matters more than you think for AI visibility. If you're not in the search index, agents can't find you. All the agent-specific optimization in the world doesn't help if you fail Gate 1.</p>

<p>Medium term: Build the agent-readable infrastructure anyway. <code>llms.txt</code>, structured context, MCP endpoints. When agents do get direct navigation (and they will), sites with this stuff ready will have a huge advantage.</p>

<p>Long term: Watch for whoever builds the resolution and trust layer. That's the Cloudflare/Let's Encrypt play for the agent web. That's where the real leverage will be.</p>

<hr>

<p>I'm going to keep poking at this. Keep trying handshake protocols that don't work. Keep asking agents about their own limitations. There's something here.</p>

<p>The agent literally told me: "Agents do not browse. They are routed." That's a different internet than the one we built. We're still figuring out what that means.</p>

        </div>
    </article>

    <section class="about-section">
        <div class="container">
            <h3>About DevExp.ai</h3>
            <p>DevExp.ai helps companies make their products discoverable to AI agents. We build the infrastructure layer between your content and the agent web—llms.txt generation, MCP servers, agent-readable APIs, and trust verification.</p>
            <p><a href="/#demo" class="cta-link">Get in Touch →</a></p>
        </div>
    </section>

    <footer class="footer">
        <div class="container">
            <a href="/">Home</a>
            <a href="/blog.html">Blog</a>
            <a href="/.well-known/agent.json">agent.json</a>
            <p style="margin-top: 24px;">© 2026 Voyant, LLC</p>
        </div>
    </footer>
</body>
</html>
